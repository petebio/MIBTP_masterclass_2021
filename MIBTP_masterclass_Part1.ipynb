{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>DNaseI-Seq workshop part 1 - Read alignment and identification of open chromatin regions</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical we will be processing two DNaseI-Seq samples obtained from mouse T-Cells\n",
    "\n",
    "Here we have two types of T-Cells (denoted as NAg and TAg) which are:\n",
    "* NAg - Naive T-Cells which have been stimulted with antigen\n",
    "* TAg - Tolerant T-Cells which have been stimulated by antigen\n",
    "\n",
    "By comparing the DHS profiles of these two samples we can show that the epigenetic response to stimulation with antigen of these two cell types is altered\n",
    "\n",
    "This data is published and is described in more detail in:\n",
    "\n",
    "Bevington et al. (2020). Chromatin Priming Renders T Cell Tolerance-Associated Genes Sensitive to Activation below the Signaling Threshold for Immune Response Genes. <i>Cell Reports</i>. 31(10), 107748\n",
    "\n",
    "* In order to save time we will only be processing data from mouse chromosome 1\n",
    "* In part 2 of this workshop you will work with processed data from these samples that contain data for the entire genome as well as additional bioloical replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Some useful Linux commands</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls # List directory - this shows what is in your folder\n",
    "mkdir # Make directory - Create a new folder\n",
    "cd # Change directory - Move into a directory\n",
    "rm # Remove file - Deletes a file - Be careful, Linux has no recycle bin!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 0. Preparation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required software into your bluebear session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module load FastQC/0.11.9-Java-11\n",
    "module load Trimmomatic/0.39-Java-11\n",
    "module load Bowtie2/2.3.5.1-GCC-8.3.0\n",
    "module load SAMtools/1.10-GCC-8.3.0\n",
    "module load picard/2.21.1-Java-11\n",
    "module load MACS2/2.2.7.1-foss-2019b-Python-3.7.4\n",
    "module load BEDTools/2.29.2-GCC-8.3.0\n",
    "module load Subread/2.0.1-GCC-8.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Move to the folder that we have set up for this class\n",
    "* Create your own folder and copy the data for this workshop to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to workshop folder\n",
    "cd /rds/projects/k/knowletj-mibtp-masterclasses/MITBP_Masterclass_2021\n",
    "\n",
    "# Create your own folder and go into it\n",
    "mkdir YOUR_NAME\n",
    "cd YOUR_NAME\n",
    "\n",
    "# Copy the fastq files to your folder\n",
    "cp ../data_for_workshop/fastq/* .\n",
    "\n",
    "# Show the files have been copied correctly\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 1. Quality assessment of raw reads and read trimming</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the read quality we will use a program called <b>fastqc</b>\\\n",
    "Run this command for both samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqc NAg_Rep1_sample.fastq.gz\n",
    "fastqc TAg_Rep1_sample.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a html report thatcan be opened in your web browser\n",
    "\n",
    "While the quality of these reads looks good, we will still carry out tread trimming to try improve it further\\\n",
    "This trimming will carry out a number of steps:\n",
    "1. Removal of sequencing adaptors\n",
    "2. Removal of low-quality bases from the 3-prime end of the sequence reads (which could contain sequencng errors)\n",
    "3. Any read that is too short after trimming is removed from the fastq file\n",
    "\n",
    "To do this we will use a tool called <b>trimmomatic</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set the path to the sequencing adaptors\n",
    "# These are stored in a fastA formatted text file\n",
    "ADAPTORS=/rds/projects/k/knowletj-mibtp-masterclasses/MITBP_Masterclass_2021/data_for_workshop/Annotation/Trimmomatic_adapters/TruSeq3-SE.fa\n",
    "\n",
    "# Now run the software\n",
    "java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar SE NAg_Rep1_sample.fastq.gz NAg_Rep1_sample_trimmed.fastq.gz ILLUMINACLIP:$ADAPTORS:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:50\n",
    "java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar SE TAg_Rep1_sample.fastq.gz TAg_Rep1_sample_trimmed.fastq.gz ILLUMINACLIP:$ADAPTORS:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the different parameters of these commands\n",
    "\n",
    "* <span style=\"color:#0000DD\">java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar SE</span> - This runs the software in single-end mode. If you have paired-end data you should instead specify PE\n",
    "* <span style=\"color:#0000DD\">NAg_Rep1_sample.fastq.gz</span> - This is the input file\n",
    "* <span style=\"color:#0000DD\">NAg_Rep1_sample_trimmed.fastq.gz</span> - This is the output file\n",
    "* <span style=\"color:#0000DD\">ILLUMINACLIP:\\$ADAPTORS:2:30:10</span> - This provides the path to the fasta file with the sequence adaptors. The numbers control how many mis-matches between the sequence read and the adaptor is acceptable to still find a match\n",
    "* <span style=\"color:#0000DD\">LEADING:3 TRAILING:3</span> - Remove bases with a quality score less than 3 from the beginning and end of the read\n",
    "* <span style=\"color:#0000DD\">SLIDINGWINDOW:4:20</span> - Trim reads from the end of the read until the average base quality in a 4bp window is above 20\n",
    "* <span style=\"color:#0000DD\">MINLEN:50</span> - Remove reads that are less than 50 bases long after trimming\n",
    "\n",
    "For more information on these go to http://www.usadellab.org/cms/?page=trimmomatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 2. Read alignment and PCR duplicate removal</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next step is to align the reads to the genome.\n",
    "* Here we will only align data to mouse chromosome 1 (mouse genome version mm10)\n",
    "\n",
    "* To do the alignment we will be using <b>bowtie2</b>\n",
    "* bowtie2 requires an indexed genome to align the data to\n",
    "* This has already been created for you so no need to do this here. But for reference a genome index can be created from the genome fastA file like so:\n",
    "bowtie2-build mm10_chr1.fa mm10\n",
    "\n",
    "* Genome fasta files can be obtained from ensembl or the UCSC genome browser\n",
    "\n",
    "Next, align the data with bowtie2 - the results will be stores in the sequence alignment map (SAM) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the NAg sample\n",
    "bowtie2 --very-sensitive-local -x /rds/projects/k/knowletj-mibtp-masterclasses/MITBP_Masterclass_2021/data_for_workshop/Genome/mm10_chr1 -U NAg_Rep1_sample_trimmed.fastq.gz -S NAg_Rep1_sample.sam\n",
    "\n",
    "# Align the TAg sample\n",
    "bowtie2 --very-sensitive-local -x /rds/projects/k/knowletj-mibtp-masterclasses/MITBP_Masterclass_2021/data_for_workshop/Genome/mm10_chr1 -U TAg_Rep1_sample_trimmed.fastq.gz -S TAg_Rep1_sample.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <span style=\"color:#0000DD\">--very-sensitive-local</span> - Controls how hard bowtie will work to find an alignment for a read. This helps improve alignment quality\\\n",
    "* <span style=\"color:#0000DD\">-x</span> - Path to the genome index files\\\n",
    "* <span style=\"color:#0000DD\">-U</span> - The reads to be aligned in fastq format. These are unpaired reads to we use the -U flag. For paired-end we would supply two files with -1 <left_reads.fastq> -2 <right_reads.fastq>\\\n",
    "* <span style=\"color:#0000DD\">-S</span> - The output file in SAM format\n",
    "\n",
    "* Before we move to the next step, the aligned reads need to be sorted by chromosome and position\n",
    "* We will also convert the files into the binary alignment map (BAM) format\n",
    "* We can do this using <b>samtools</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools sort -o NAg_Rep1_sample.bam NAg_Rep1_sample.sam\n",
    "samtools sort -o TAg_Rep1_sample.bam TAg_Rep1_sample.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* During the library prep step the fragments to be sequenced were amplified using PCR\n",
    "* As a result, we might find that we have multiple identical reads that actually represent the same DNA fragment\n",
    "* We may want to remove these to avoid any potential artefacts from over-amplified fragments\n",
    "* <b>Picard Tools</b> is useful for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java -jar $EBROOTPICARD/picard.jar MarkDuplicates I=NAg_Rep1_sample.bam O=NAg_Rep1_sample_rmdup.bam M=NAg_Rep1_sample_picard_metrics.txt AS=true REMOVE_DUPLICATES=true\n",
    "java -jar $EBROOTPICARD/picard.jar MarkDuplicates I=TAg_Rep1_sample.bam O=TAg_Rep1_sample_rmdup.bam M=TAg_Rep1_sample_picard_metrics.txt AS=true REMOVE_DUPLICATES=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what each of these options do:\n",
    "* <span style=\"color:#0000DD\">I=NAg_Rep1_sample.bam</span> - The input file which is our sorted bam file \n",
    "* <span style=\"color:#0000DD\">O=NAg_Rep1_sample_rmdup.bam</span> - The output file\n",
    "* <span style=\"color:#0000DD\">M=NAg_Rep1_sample_picard_metrics.txt</span> - Ouput some metrics about the duplicate removal\n",
    "* <span style=\"color:#0000DD\">AS=true</span> - Assume the reads are sorted\n",
    "* <span style=\"color:#0000DD\">REMOVE_DUPLICATES=true</span> - Remove PCR duplicated reads\n",
    "\n",
    "We also need to create an index for the aligned reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools index NAg_Rep1_sample_rmdup.bam\n",
    "samtools index TAg_Rep1_sample_rmdup.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 3. Peak calling and filtering peaks</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next step will be to identify potential open chromatin regions - which we can also call peaks\n",
    "* To do this we will use <b>MACS2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macs2 callpeak -t NAg_Rep1_sample_rmdup.bam -n NAg_Rep1_sample --keep-dup all --nomodel -g mm -B --trackline\n",
    "macs2 callpeak -t TAg_Rep1_sample_rmdup.bam -n TAg_Rep1_sample --keep-dup all --nomodel -g mm -B --trackline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <span style=\"color:#0000DD\">-t NAg_Rep1_sample_rmdup.bam</span> - The aligned reads from the treatment file - in this case this is sorted, de-duplicated alignment that we have made\\\n",
    "* <span style=\"color:#0000DD\">-n NAg_Rep1_sample</span> - What to call the output files\\\n",
    "* <span style=\"color:#0000DD\">--keep-dup all</span> - Tells macs not to perform PCR duplicate removal - we have already done this\\\n",
    "* <span style=\"color:#0000DD\">--nomodel</span> - Turns off MAC's peak shiting model. This model is useful for ChIP-Seq but for other types of data like DNaseI of ATAC-Seq we do not need this\\\n",
    "* <span style=\"color:#0000DD\">-g mm</span> - This specifies the effective genome size. MACS2 has some genome sizes for common model organisms built in built-in. Here we specific mouse (mus musculus) using the abbreviation mm\\\n",
    "* <span style=\"color:#0000DD\">-B --trackline</span> - These options are used to produce a bedGraph file. This file can be uploaded to the UCSC genome browser\n",
    "\n",
    "This produces a number of output files - They are:\n",
    "* <b>NAg_Rep1_sample_peaks.narrowPeak</b> - A BED file that contains the peak positions called by MACS2 along with p-value and q-value of those peaks\n",
    "* <b>NAg_Rep1_sample_summits.bed</b> - A BED file with the summit position for every peak called\n",
    "* <b>NAg_Rep1_sample_peaks.xls</b> - A tab-delimited file which contains the peak and summit positions as well as some other useful statistics (peak height, pvalue, qvalue)\n",
    "* <b>NAg_Rep1_sample_control_lambda.bdg</b> - BedGraph for the input sample (used only with chip)\n",
    "* <b>NAg_Rep1_sample_treat_pileup.bdg</b> - BedGraph for the treatment sample (can be uploaded to UCSC genome browser)\n",
    "\n",
    "Next, count the number of peaks called by MACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l NAg_Rep1_sample_summits.bed\n",
    "wc -l TAg_Rep1_sample_summits.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will filter the peaks. We will do this in two steps:\n",
    "1. Remove small background peaks\n",
    "2. Remove blacklisted regions\n",
    "\n",
    "The below set of commands use the linux pipe to reads the peaks.xls file produced by macs and extract peaks with a height >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat NAg_Rep1_sample_peaks.xls | grep -v '#' | grep -v 'start' | awk '$6 >= 10' | awk '{print $1\"\\t\"$5\"\\t\"$5}' > NAg_Rep1_sample_filtered_summits.bed\n",
    "cat TAg_Rep1_sample_peaks.xls | grep -v '#' | grep -v 'start' | awk '$6 >= 10' | awk '{print $1\"\\t\"$5\"\\t\"$5}' > TAg_Rep1_sample_filtered_summits.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what each of these commands is doing:\n",
    "* <span style=\"color:#0000DD\">cat NAg_Rep1_sample_peaks.xls</span> - This reads the file\n",
    "* <span style=\"color:#0000DD\">grep -v '#' | grep -v 'start'</span> - This removes the headers from the file (i.e. lines that begin with # or contain the word start)\n",
    "* <span style=\"color:#0000DD\">awk '$6 >= 10'</span> - Keep only peaks with a value >= 10 in column 6\n",
    "* <span style=\"color:#0000DD\">awk '{print $1\"\\t\"$5\"\\t$5}'</span> - Keep only the 1st column (which contains the chromosome) and the 5th column (summit position) twice - this ensures we have BED formatted file\n",
    "* <span style=\"color:#0000DD\">> NAg_Rep1_sample_filtered_summits.bed</span> - The output file - A BED file\n",
    "\n",
    "Count the number of peaks kept after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l NAg_Rep1_sample_filtered_summits.bed\n",
    "wc -l TAg_Rep1_sample_filtered_summits.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next we will remove blacklisted regions\n",
    "* These are regions which are known to give unusually high read coverage and are considered an artefact\n",
    "* The mm10 blacklist can be found here as a bed file:\n",
    "* It has already been downladed for you so you can do the filtering as so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the blacklist bed file\n",
    "BLACKLIST=/rds/projects/k/knowletj-mibtp-masterclasses/MITBP_Masterclass_2021/data_for_workshop/Annotation/mm10-blacklist.v2.bed\n",
    "\n",
    "bedtools intersect -v -a NAg_Rep1_sample_filtered_summits.bed -b $BLACKLIST > NAg_Rep1_sample_filtered_noBlackList_summits.bed\n",
    "bedtools intersect -v -a TAg_Rep1_sample_filtered_summits.bed -b $BLACKLIST > TAg_Rep1_sample_filtered_noBlackList_summits.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we used the <b>intersect</b> function from <b>bedtools</b>\n",
    "The command can be broken down like so:\n",
    "* <span style=\"color:#0000DD\">-a NAg_Rep1_sample_filtered_summits.bed</span> - This is bed file A - Contains our filtered peaks\n",
    "* <span style=\"color:#0000DD\">-b \\$BLACKLIST</span> - This is bed file B - A bed file of blacklisted peaks to remove\n",
    "* <span style=\"color:#0000DD\">-v</span> - This option tells bedtools to only keep sites from file A that are not in file B\n",
    "* <span style=\"color:#0000DD\">>NAg_Rep1_sample_filtered_noBlackList_summits.bed</span> - The output file\n",
    "\n",
    "Count the number of peaks after removing blacklisted sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l NAg_Rep1_sample_filtered_noBlackList_summits.bed\n",
    "wc -l TAg_Rep1_sample_filtered_noBlackList_summits.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 4. Create a peak union and count reads</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can create a table of read counts for the differential peak analysis, we must first combine all the peaks from our samples into a single file\\\n",
    "We refer to this a the peak union\n",
    "\n",
    "Our criteria for merging peaks is as follows:\n",
    "* If the summit positions of two peaks is within 200bp we consider them to be the same peak and merge them\n",
    "\n",
    "\n",
    "To do this we will first need to do two things:\n",
    "1. Extend the peaks by +/- 100bp to create a 200bp peak window. This is done using the <b>slop</b> function in <b>bedtools</b>\n",
    "2. Concatenate all peaks into one single bed file. This file then has to be sorted by chromosome and position. For this we will use the <b>cat</b> function in Linux and the <b>sort</b> function in <b>bedtools</b>\n",
    "\n",
    "Finally we can merge overlapping peaks using the <b>merge</b> function in <b>bedtools</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bedtools slop we need a table of chromosome sizes. Set the path to this table like so\n",
    "CHROMSIZE=/rds/projects/k/knowletj-mibtp-masterclasses/MITBP_Masterclass_2021/data_for_workshop/Annotation/mm10.chrom.sizes\n",
    "\n",
    "# Now run bedtools slop\n",
    "bedtools slop -b 100 -i NAg_Rep1_sample_filtered_noBlackList_summits.bed -g $CHROMSIZE > NAg_Rep1_sample_filtered_noBlackList_peaks.bed\n",
    "bedtools slop -b 100 -i TAg_Rep1_sample_filtered_noBlackList_summits.bed -g $CHROMSIZE > TAg_Rep1_sample_filtered_noBlackList_peaks.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what these options do:\n",
    "* <span style=\"color:#0000DD\">-b 100</span> - extend summit by 100bp in both directions\n",
    "* <span style=\"color:#0000DD\">-i NAg_Rep1_sample_filtered_noBlackList_summits.bed</span> - The input file\n",
    "* <span style=\"color:#0000DD\">-g mm10.chromSizes</span> - A file that contains the size (in base pairs) of each of the chromosomes in mm10\n",
    "* <span style=\"color:#0000DD\">> NAg_Rep1_sample_filtered_noBlackList_peaks.bed</span> - The output file\n",
    "\n",
    "Next, we can combine the two bed files in to a single file\n",
    "At this point we also need to sort the peaks and then merge peaks which are overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat NAg_Rep1_sample_filtered_noBlackList_peaks.bed TAg_Rep1_sample_filtered_noBlackList_peaks.bed > Merged.bed\n",
    "bedtools sort -i Merged.bed > Merged_sorted.bed\n",
    "bedtools merge -i Merged_sorted.bed > Peak_Union.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of peaks in the peak union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc -l Peak_Union.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can count the number of reads per peak using <b>featureCounts</b>. \n",
    "This is what we will use for the differential peak analysis\n",
    "\n",
    "featureCounts will not read BED files directly, so first we need to convert the peak union bed file into something featureCounts can read \\\n",
    "We will use the SAF file format here, which is extremely similar to a bed file with two extra columns\n",
    "\n",
    "For this we can use <b>awk</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Peak_Union.bed | awk '{print $1\":\"$2\":\"$3\"\\t\"$1\"\\t\"$2\"\\t\"$3\"\\t.\"}' > Peak_Union.saf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a file that looks something like:\n",
    "\n",
    "| PeakID | Chromosome | Start | End | Strand |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| chr7\\:110166237:110166637 | chr7 | 110166237 | 110166637 | . |\n",
    "| chr17\\:79298879:79299279 | chr17 | 79298879 | 79299279 | . |\n",
    "| chr19\\:16789975:16790375 | chr19 | 16789975 | 16790375 | . |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first column is just the peak coordinate separated by :\n",
    "* The next 3 columns are the peak position in a BED like format\n",
    "* The final column is the strand - since this is genomic data we do not actually have stranded data so a . will work fine here\n",
    "\n",
    "The column headers can be left out\n",
    "\n",
    "Now, we can count reads using <b>featureCounts<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCounts -F SAF -a Peak_Union.saf -o NAgTAg_DHS_rawCounts.tsv NAg_Rep1_sample_rmdup.bam TAg_Rep1_sample_rmdup.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what these options do:\n",
    "* <span style=\"color:#0000DD\">-F SAF</span> - tells featureCounts our peaks are in the SAF format\n",
    "* <span style=\"color:#0000DD\">-a Peak_Union.saf</span> - The input file\n",
    "* <span style=\"color:#0000DD\">-o NAgTAg-DHS_rawCounts.tsv</span> - The output file\n",
    "* <span style=\"color:#0000DD\">NAg_Rep1_sample_rmdup.bam TAg_Rep1_sample_rmdup.bam</span> - Here we provide the bam files we made earlier - use these to count the reads\n",
    "\n",
    "The resulting file can be used for downstream analysis in DESeq2 or other programs\n",
    "\n",
    "# End of workshop part 1. Move to part 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
